{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Machine Learning: FFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\t\t\n",
    "    data = arff.loadarff(filename)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    # Convert string attribute to integer\n",
    "    df.outlook = pd.Categorical(pd.factorize(df.outlook)[0])\n",
    "    df.outlook = pd.to_numeric(df.outlook, errors='coerce')\n",
    "    df.windy = pd.Categorical(pd.factorize(df.windy)[0])\n",
    "    df.windy = pd.to_numeric(df.windy, errors='coerce')\n",
    "    df.play = pd.Categorical(pd.factorize(df.play)[0])\n",
    "    df.play = pd.to_numeric(df.play, errors='coerce')\n",
    "\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_size=0.1):\n",
    "    y = data.play\n",
    "    x = data.drop('play',axis=1)\n",
    "#     scaler = preprocessing.MinMaxScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Train Accuracy:  0.75\n",
      "[1, 1]\n",
      "Test Predict Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "class FFNN: \n",
    "    def __init__(self, nb_feature, nb_hidden_layer, nb_nodes):\n",
    "        self.nb_output_layer = 1\n",
    "        self.nb_feature = nb_feature\n",
    "        self.nb_hidden_layer = nb_hidden_layer\n",
    "        self.nb_nodes = nb_nodes\n",
    "        self.nb_weight_layer = nb_hidden_layer + 1\n",
    "\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.output_neurons = []\n",
    "        self.feature_neurons = []\n",
    "        self.hidden_neurons = []\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x)) \n",
    "\n",
    "    def count_error(self, learning_rate, target_output):\n",
    "        return pow((learning_rate - target_output),2)/2\n",
    "\n",
    "    def init_weights(self):\n",
    "        for i in range (self.nb_weight_layer):\n",
    "            temp_weight = []\n",
    "            if i == 0:\n",
    "                temp_weight = np.random.randn(self.nb_feature, self.nb_nodes)\n",
    "            elif i < self.nb_weight_layer - 1:\n",
    "                temp_weight = np.random.randn(self.nb_nodes, self.nb_nodes)\n",
    "            elif i == self.nb_weight_layer - 1:\n",
    "                temp_weight = np.random.randn(self.nb_nodes, self.nb_output_layer)\n",
    "            self.weights.append(temp_weight)\n",
    "            self.bias.append(np.random.random())\n",
    "\n",
    "    def get_sigmoid_value(self, m=None, n=None, output=False):\n",
    "        if output:\n",
    "            m = self.nb_weight_layer-1\n",
    "            n = 0\n",
    "        if m == 0:\n",
    "            previous_layer = self.feature_neurons  \n",
    "        else :\n",
    "            previous_layer = self.hidden_neurons[m-1]\n",
    "        weight_layer = self.weights[m]\n",
    "        sigmoid_value = 0\n",
    "\n",
    "        for i in range(len(previous_layer)):\n",
    "            sigmoid_value += previous_layer[i] * weight_layer[i, n]\n",
    "        sigmoid_value = self.sigmoid(sigmoid_value + self.bias[m])\n",
    "        return sigmoid_value\n",
    "\n",
    "    def get_output(self, input):\n",
    "        self.feature_neurons = []\n",
    "        self.hidden_neurons = []\n",
    "        for item in input:\n",
    "            self.feature_neurons.append(item)\n",
    "\n",
    "        for i in range(self.nb_hidden_layer):\n",
    "            temp_hidden_layer = []\n",
    "            for j in range(self.nb_nodes):\n",
    "                temp_hidden_layer.append(self.get_sigmoid_value(i, j))\n",
    "            self.hidden_neurons.append(temp_hidden_layer)\n",
    "        output = self.get_sigmoid_value(output=True)\n",
    "        return output\n",
    "\n",
    "    def fit(self, x_train, y_train, batch_size, momentum=0.001, learning_rate=0.5, epoch=5):\n",
    "        self.init_weights()\n",
    "        for i in range(epoch):\n",
    "            #masuk ke epoch\n",
    "            for\tj in range(0, len(y_train), batch_size):\n",
    "                #masuk ke batch\n",
    "                x_mini = x_train[j:j+batch_size]\n",
    "                y_mini = y_train[j:j+batch_size]\n",
    "                outputs = 0\n",
    "                for x,y in zip(x_mini,y_mini):\n",
    "                    self.output_neurons.append(self.get_output(x)-y)\n",
    "                avg_error = np.average(self.output_neurons)\n",
    "                    # Update weight with gradient descent\n",
    "                self.update_weight(learning_rate, momentum, j, i, avg_error)\n",
    "                self.output_neurons = []             \n",
    "    \n",
    "    def update_weight(self, learning_rate, momentum, batch, epoch, outputs):\n",
    "        previous_layer = []\n",
    "        next_layer = []\n",
    "        \n",
    "        for i in reversed(range(self.nb_weight_layer)):\n",
    "            previous_weight = self.weights[i]\n",
    "            if (i == 0):\n",
    "                previous_layer = self.feature_neurons\n",
    "            else:\n",
    "                previous_layer = self.hidden_neurons[i-1]\n",
    "                \n",
    "            if (i == self.nb_weight_layer-1):\n",
    "                next_layer = outputs\n",
    "            else:\n",
    "                next_layer = self.hidden_neurons[i]\n",
    "\n",
    "                \n",
    "            prevm = np.matrix(previous_layer)\n",
    "            nextm = np.matrix(next_layer)\n",
    "            \n",
    "            self.bias[i] -= learning_rate*(outputs) + momentum*self.bias[i]\n",
    "            self.weights[i] -= (1/(i+1))*learning_rate*(prevm.T.dot(nextm)) + momentum*self.weights[i]\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y_pred = []\n",
    "        \n",
    "        for x in X:\n",
    "#             print(self.get_output(x))\n",
    "            Y_pred.append(self.get_output(x))\n",
    "\n",
    "        return Y_pred\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load('weather.arff')\n",
    "    X_train, X_test, y_train, y_test = split(data, 0.05)\n",
    "    ffnn = FFNN(X_train.shape[1],2,3)\n",
    "    ffnn.fit(X_train, y_train, batch_size=2, epoch=100)\n",
    "    Y_pred = ffnn.predict(X_test)\n",
    "    Ytrain_pred = ffnn.predict(X_train)\n",
    "#     print(\"Test\", X_test)\n",
    "#     print(\"Train\", X_train)\n",
    "\n",
    "    y_pred_binarised_train = []\n",
    "    for item in Ytrain_pred:\n",
    "        if (item >= 0.5):\n",
    "            y_pred_binarised_train.append(1)\n",
    "        else:\n",
    "            y_pred_binarised_train.append(0)\n",
    "            \n",
    "    print(y_pred_binarised_train)\n",
    "    print(\"Train Accuracy: \",accuracy_score(y_pred_binarised_train, y_train))\n",
    "\n",
    "    y_pred_binarised_test = []\n",
    "    for item in Y_pred:\n",
    "        if (item >= 0.5):\n",
    "            y_pred_binarised_test.append(1)\n",
    "        else:\n",
    "            y_pred_binarised_test.append(0)\n",
    "            \n",
    "    print(y_pred_binarised_test)\n",
    "    print(\"Test Predict Accuracy: \",accuracy_score(y_pred_binarised_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
